--emb_size=200
--vocab_size=93218
--num_layers=1
--hidden_size=512
--num_steps_train=35
--num_steps_eval=35
--optimizer_algo=adam
--learning_rate=1.0e-3
--emb_keep_prob=1.0
--input_keep_prob=1.0
--output_keep_prob=1.0
--state_keep_prob=1.0
--l2_reg=0.0
--clip_norm=8.0
--batch_size_train=64
--batch_size_eval=64
--num_epochs=10
--evaluate_every=5000
--checkpoint_every=5000
--train_path=../lambada-dataset/train_novels_chunks.txt
--dev_path=../lambada-dataset/lambada_control_test_data_plain_text.txt