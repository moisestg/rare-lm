--emb_size=150
--pretrained_emb=word2vec
--vocab_size=44636
--num_layers=1
--hidden_size=512
--num_steps_train=100
--num_steps_eval=100
--optimizer_algo=adam
--learning_rate=1.0e-3
--emb_keep_prob=1.0
--input_keep_prob=1.0
--output_keep_prob=1.0
--state_keep_prob=1.0
--l2_reg=0.0
--clip_norm=1.0
--attention_length=100
--batch_size_train=64
--batch_size_eval=64
--num_epochs=10
--evaluate_every=5000
--checkpoint_every=5000
--train_path=../lambada-dataset/capitalized/capitalized_train_small.txt
--dev_path=../lambada-dataset/capitalized/capitalized_dev.txt
--test_path=../lambada-dataset/capitalized/capitalized_test.txt